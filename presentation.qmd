---
title: "Consumer Behaviour Analysis"
subtitle: "INFO 523 - Fall 2023 - Project Final"
author: "Pattern Pioneers - Vishal, Joel, Pranshu, Shashwat, Bharath"
title-slide-attributes:
  data-background-image: images/presentation.jpg
  data-background-size: stretch
  data-background-opacity: "0.8"
  data-slide-number: none
format:
  revealjs:
    theme:  ['data/customtheming.scss']
    transition: slide
    background-transition: fade
    logo: images\pp_logo.png
    footer: "[Pattern Pioneers](https://info-523-exercises.github.io/project-final-Pattern-Pioneers/)"
    scrollable: true
  
editor: visual
execute:
  echo: false
---

```{r install_packages, include=FALSE}
### Loading the required libraries
if (!require(pacman))
  install.packages(pacman)

pacman::p_load(tidyverse,   # Data wrangling
               dlookr,      # Exploratory Data Analysis
               formattable, # Present neat table format
               gt,          # Alternating formatting for the tables
               gtsummary,
               here,
               nnet,
               janitor,
               corrplot,
               dplyr,
               caret,
               formattable,
               rpart,
               rpart.plot)       # Summary for the tables
```

```{r theme, include=FALSE}
# setting theme for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 14, base_family = "sans"))

# setting width of code output
options(width = 65)

# setting figure parameters for knitr
knitr::opts_chunk$set(
  fig.width = 8,        # 8" width
  fig.asp = 0.618,      # the golden ratio
  fig.retina = 1,       # dpi multiplier for displaying HTML output on retina
  fig.align = "center", # center align figures
  dpi = 140             # higher dpi, sharper image
)
```

```{r read_data, include=FALSE}

# Using the original data
# Loading the csv into a variable using read_csv

data <- read_csv(here("data", "Amazon_Customer_Behavior_Survey.csv"))

# Removing unwanted column like "timestamp".
data <- data %>% 
  select(-Timestamp) %>%
  clean_names()
```

## Our Dataset {auto-animate="true"}

::: incremental
-   **Amazon Consumer Behaviour Dataset** that we came across in [Kaggle](https://www.kaggle.com/datasets/swathiunnikrishnan/amazon-consumer-behaviour-dataset/data) was to unveil some customer insights.

-   It has a comprehensive collection of customer interactions, browsing patterns within the Amazon ecosystem.

-   It includes a wide range of variables such as customer demographics, user interaction, and reviews.

-   The dataset aims to provide insights into customer preferences, shopping habits, and decision-making processes on the Amazon platform
:::

## Our Dataset {.smaller}

| Variable                              | Description                                                                                |
|-------------------------|------------------------------------------------|
| Purchase_Frequency                    | How frequently does the user make purchases on Amazon?                                     |
| Product_Search_Method                 | How does the user search for products on Amazon?                                           |
| Customer_Reviews_Importance           | How important are customer reviews in users decision-making process?                       |
| age                                   | age                                                                                        |
| Gender                                | gender                                                                                     |
| Browsing_Frequency                    | How often does the user browse Amazon's website or app?                                    |
| Purchase_Categories                   | What product categories does the user typically purchase on Amazon?                        |
| Cart_Completion_Frequency             | How often do user complete the purchase after adding products to their cart?               |
| Personalized_Recommendation_Frequency | How often do user receive personalized product recommendations from Amazon?                |
| Search_Result_Exploration             | Does the user tend to explore multiple pages of search results or focus on the first page? |

## EDA Results- Top Improvement Areas {auto-animate="true"}

```{r eda_1}
# Calculate the counts of each category
improvement_counts <- data %>%
  group_by(improvement_areas) %>%
  summarize(count = n()) %>%
  arrange(desc(count)) %>%
  ungroup()

# Get the top 4 categories
top_improvement_areas <- head(improvement_counts, 4)$improvement_areas

# Create a new column 'grouped_improvement_areas' where categories outside the top 4 are labeled 'Others'
data <- data %>%
  mutate(grouped_improvement_areas = ifelse(improvement_areas %in% top_improvement_areas, 
                                            improvement_areas, 
                                            'Others'))

# Reorder the factor levels to ensure "Others" is at the end
data$grouped_improvement_areas <- factor(data$grouped_improvement_areas,
                                         levels = c(top_improvement_areas, "Others"))

# Plot with top 4 categories and 'Others' at the end
ggplot(data, aes(x=grouped_improvement_areas, fill=grouped_improvement_areas)) +
  geom_bar(color="black") +
  theme_minimal(base_size = 16) +
  theme(axis.text.x = element_text(angle = 0),
        legend.position = "none") +
  labs(title = "Distribution of Top Improvement Areas", 
       x = "Improvement Areas", 
       y = "Count") +
  scale_fill_brewer(palette="Set3")  # Using a ColorBrewer palette for fill colors

```

## Question 1 {.smaller}

What are the factors influencing the customer's decision to abandon a purchase in their cart on Amazon?

## Approach For Question 1 {.smaller}

::: incremental
-   **Data Cleaning:**- Our analysis begins with precise exploratory data analysis (EDA) in R, focusing on key variables like Purchase_Frequency, Product_Search_Method, and Customer_Reviews_Importance to understand their impact on cart abandonment. During data cleaning, we ensure proper formatting and address missing values in columns age, Gender, and Browsing_Frequency.

-   We then apply statistical techniques like neural networks and decision trees to assess the influence of factors such as Personalized_Recommendation_Frequency and Search_Result_Exploration on cart abandonment.

-   **Visualization**- For visualisation we utilize the ggplot2 package for creating comprehensive graphics, including correlation heat-maps and bar charts, to reveal insights into the interplay between cart abandonment and customer behavior metrics, aiming to enhance the shopping experience and reduce cart abandonment rates effectively.
:::

## Pre Processing {.smaller}

- Upon examining the data, we observed that a single purchase, represented by a row, was associated with multiple purchase categories.


```{r, warning=FALSE,echo=FALSE}
data|>head()|>formattable()
```

## Pre Processing {.smaller}

- To address this issue and ensure data consistency, we chose to split the categories into separate rows.

```{r,warning=FALSE,echo=FALSE,eval=TRUE}
df_expand <- data %>%
  separate_rows(purchase_categories, sep=";") %>%
  rename(purchase_category = purchase_categories)

df_expand |> head() |> formattable()
```

## EDA Results - Age Distribution {auto-animate="true"}

```{r eda_2}
# Distribution of Age Among Respondents with a color
ggplot(data, aes(x=age)) +
  geom_histogram(binwidth = 1, fill="skyblue", color="black") +  # Setting fill and outline color for the bars
  theme_minimal(base_size = 16) +
  labs(title = "Distribution of Age Among Respondents", x = "Age", y = "Count")
```

## EDA Results - Purchase Frequency {auto-animate="true"}

```{r eda_3}

# Distribution of Purchase Frequency with colors
ggplot(data, aes(x=purchase_frequency, fill=purchase_frequency)) +
  geom_bar(color="black") +
  scale_fill_brewer(palette="Set3") +  # Using a ColorBrewer palette for fill colors
  theme_minimal(base_size = 16) +
  theme(axis.text.x = element_text(angle = 0),
        legend.position = "none") +
  labs(title = "Distribution of Purchase Frequency", x = "Purchase Frequency", y = "Count")
```



```{r new_df, include=FALSE}
# creating a new dataframe by selecting only the columns of our focus

new_df <-
  data %>% select(
    purchase_frequency,
    product_search_method,
    customer_reviews_importance,
    cart_abandonment_factors
  )
```

```{r refactor_new_df, include=FALSE}
# modifying the column data type to factor and then to integer
new_df$purchase_frequency <- as.factor(new_df$purchase_frequency)
new_df$purchase_frequency <- as.integer(new_df$purchase_frequency)

unique(new_df$purchase_frequency)

# modifying the column data type to factor and then to integer
new_df$product_search_method <-
  as.factor(new_df$product_search_method)
new_df$product_search_method <-
  as.integer(new_df$product_search_method)

unique(new_df$product_search_method)

# modifying the column data type to factor and then to integer
new_df$cart_abandonment_factors <-
  as.factor(new_df$cart_abandonment_factors)
new_df$cart_abandonment_factors <-
  as.integer(new_df$cart_abandonment_factors)

unique(new_df$cart_abandonment_factors)

# modifying the column data type to factor and then to integer
new_df$customer_reviews_importance <-
  as.factor(new_df$customer_reviews_importance)
new_df$customer_reviews_importance <-
  as.integer(new_df$customer_reviews_importance)

unique(new_df$customer_reviews_importance)

# removing missing values from the dataframe
new_df = na.omit(new_df)
```

```{r correlation, include=FALSE}
# creating correlation matrix using cor()
correlation_matrix <- cor(new_df)

# Display the correlation matrix
correlation_matrix
```



## Models Used
::: incremental
- Neural Networks
- Decision Tree
:::


## Correlation Matrix for Consumer Behaviour
```{r corrplot}
# Visualize correlation matrix using correlation plot


corrplot(correlation_matrix, method = "color")
```

## Modeling - NNET {auto-animate="true"}

```{r traning_1, include=FALSE}
set.seed(123) # For reproducibility

# training the dataset by splitting the data to 80% training
train_index <-
  sample(1:nrow(new_df), 0.8 * nrow(new_df)) # 80% for training

# getting train and test data
train_data <- new_df[train_index,]
test_data <- new_df[-train_index,]

ncol(train_data)
```

```{r model, message=FALSE, output=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: "Model for Question 1"



# calling the nnet model with Cart_Abandonment_Factors and Product_Search_Method being our focus

model <- nnet(
  cart_abandonment_factors ~ product_search_method,
  data = train_data,
  size = 100,
  maxit = 1000
)

```

```{r predictions}

# generating predictions on the test data using the created model above
predictions <- predict(model, newdata = test_data)

# getting accuracy of our predictions
accuracy <-
  mean(predictions == test_data$cart_abandonment_factors) * 100

```

## Modeling - Decision Tree {auto-animate="true"}

```{r dtree, message=FALSE}
# Using a decision tree classifier
# Convert factors to categorical
data$cart_abandonment_factors <- as.factor(data$cart_abandonment_factors)
data$product_search_method <- as.factor(data$product_search_method)

# Splitting the data (example using 70%-30% split)
set.seed(123)  # for reproducibility
splitIndex <- createDataPartition(data$cart_abandonment_factors, p = 0.70, list = FALSE)
train <- data[splitIndex, ]
test <- data[-splitIndex, ]

# Train the model
tree_model <- rpart(cart_abandonment_factors ~ product_search_method, data = train, method = "class")

# Evaluate the model (using test set)
predictions <- predict(tree_model, test, type = "class")

# Model accuracy
accuracy <- sum(predictions == test$cart_abandonment_factors) / nrow(test)

# Visualize the tree
rpart.plot(tree_model)
```
- **Key Takeaway-** The most important factor for people abandoning there carts was that "they found a better price elsewhere"

## Question 2 {.smaller}

Which demographic (on the basis of gender and age) is most likely to purchase a particular product category?

## Approach For Question 2 {.smaller}

::: incremental
The approach that we took to solve determine which demographic is most likely to purchase a particular product category is as follows:

-   **Data Cleaning:** We checked the data set for any inconsistencies like missing values or incorrect data. Then we tried to handle the outliers if they needed to be removed.

-   **Summary statistics:** After data cleaning we performed the summary statistics for important columns like purchase category, age group, gender which helped us understand the characteristics and the distribution of data.

-   **Visualization:** After a few steps of data transformation which included splitting the rows having multiple purchase categories into multiple rows with same data in other columns we performed some visualizations using ggplot to represent the data with the bar plots which helped us to figure out some trends and patterns of our data.

-   **Modelling:** In the final part we performed statistical modelling to assess the likelihood of purchasing different product categories based on demographic variables like age and gender. We achieved this goal by using logistic regression models to predict the probability of a particular demographic to purchase each category.
:::

## EDA Results {auto-animate="true"}

```{r plot_data}
# Age distribution
ggplot(data, aes(x=age)) + geom_histogram(bins=30, fill="blue", color="black") +
  labs(title="Age Distribution", x="Age", y="Frequency") +
  theme_minimal(base_size = 16)
```

## EDA Results {auto-animate="true"}

```{r eda_results}
# Gender distribution
ggplot(data, aes(x=gender)) + geom_bar(fill="orange") +
  labs(title="Gender Distribution", x="Gender", y="Count") +
  theme_minimal(base_size = 16)

```

```{r age_group_data, include=FALSE}
# Creating afe group based on age
data$age_group <- cut(data$age, breaks=c(0, 18, 25, 35, 45, 55, 65, 100),
                    labels=c('0-18', '19-25', '26-35', '36-45', '46-55', '56-65', '65+'))

```

```{r splitting purchase categories, include=FALSE}
# We are going to split the rows having multiple purchase categories into multiple rows with same data in other columns but split up with respect to purchasing categories.
# Splitting 'Purchase_Categories'
df_expanded <- data %>%
  separate_rows(purchase_categories, sep=";") %>%
  rename(purchase_category = purchase_categories)

```

## EDA Results {auto-animate="true"}

```{r age_gender}
# Plotting a stacked barplot for representing purchase categories across different age groups
ggplot(df_expanded, aes(x=purchase_category, fill=age_group)) +
  geom_bar(position = "fill") +
  coord_flip() +
  scale_fill_brewer(palette="Set3") +
  labs(title="Purchase Categories Across Age Groups", x="Purchase Category", y="Count") +
  theme_minimal(base_size = 16)
```

## EDA Results {auto-animate="true"}

```{r eda_21}
# Plotting a stacked barplot for representing purchase categories across different genders
ggplot(df_expanded, aes(x=purchase_category, fill=gender)) +
  geom_bar(position = "fill") +
  coord_flip() +
  scale_fill_brewer(palette="Set3") +
  labs(title="Purchase Categories Across Genders", x="Purchase Category", y="Count") +
  theme_minimal(base_size = 16)
```

```{r log_regr, include=FALSE}

# Preparing the data for logistic regression
df_expanded <- df_expanded |>
    mutate(purchase_category = ifelse(is.na(purchase_category), 
                                   NA, 
                                   tolower(gsub(" ", "_", purchase_category))))

unique_categories <- unique(df_expanded$purchase_category)
models <- list()
reports <- list()
```

## Modeling

```{r predictions_2, message=FALSE, output=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: "Model for Question 2"



for (category in unique_categories) {
  # Binary variable for each category
  df_expanded[[category]] <- ifelse(df_expanded$purchase_category == category, 1, 0)
  
  # Model
  model_formula <- as.formula(paste(category, "~ age_group + gender"))
  model <- multinom(model_formula, data=df_expanded)
  
  # Store the model
  models[[category]] <- model
  
  # Evaluation
  predictions <- predict(model, df_expanded)
  reports[[category]] <- confusionMatrix(data=factor(predictions, levels=c(0,1)), 
                                         reference=factor(df_expanded[[category]], levels=c(0,1)))
}
```

```{r results, include=FALSE}

# Displaying the report for an example category
print(reports[[unique_categories[1]]])
```

## Challenges faced {auto-animate="true"}

::: incremental
-   Insufficient amount of data to conduct a full fledged analysis on cart abandonment factors.
-   The dataset contained time value for only a couple of weeks.
-   Class Imbalance issue while modeling using logistic regression.
-   Some models we tried are over fitting the data like random forest.
:::

## Outcome {.smaller auto-animate="true"}

::: incremental
-   Exploring the pros and cons of neural networks in our dataset.
-   Handling datasets and experimenting with models that can be applied for real-time use cases.
:::
