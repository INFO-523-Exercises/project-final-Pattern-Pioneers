---
title: "Proposal title"
subtitle: "Proposal"
author: 
  - name: "Pattern Pioneers - "
    affiliations:
      - name: "School of Information, University of Arizona"
description: ""
format:
  html:
    code-tools: true
    code-overflow: wrap
    code-line-numbers: true
    embed-resources: true
editor: visual
code-annotations: hover
categories: 
  - Data Mining
execute:
  warning: false
---

## Load required packages

```{r load_pkgs, message=FALSE, output=FALSE}
#| code-fold: true
#| code-summary: "Installed Packages"

### GETTING THE LIBRARIES
if (!require(pacman))
  install.packages(pacman)

pacman::p_load(tidyverse,   # Data wrangling
               dlookr,      # Exploratory Data Analysis
               formattable, # Present neat table format
               gt,          # Alternating formatting for the tables
               gtsummary)   # Summary for the tables
```

## Dataset

```{r}
#| label: load-dataset
#| message: false
#| code-fold: true

# Using the original data
# Loading the csv into a variable using read_csv

data <- read_csv("data/Amazon_Customer_Behavior_Survey.csv")

# Removing unwanted column like "timestamp".

data <- data %>% select(-Timestamp)


```

This is a dataset collected for analyzing the behavioral analysis of Amazon's consumers consists of a comprehensive collection of customer interactions,browsing patterns within the Amazon ecosystem. It includes a wide range of variables such as customer demographics, user interaction, and reviews. The dataset aims to provide insights into customer preferences, shopping habits, and decision-making processes on the Amazon platform. By analyzing this dataset, researchers and analysts can gain a deeper understanding of consumer behavior, identify trends, optimize marketing strategies, and improve the overall customer experience on Amazon. The Dataset contains `N=602` observations.

## Examine data

Using dlookr's `describe()` and `diagnose()` - some basic EDA

```{r}
#| label: data-summary-describe
#| message: false
#| code-fold: true
# Summary statistics of numerical column

data |> 
    describe() |>
  formattable()
```

```{r}
#| label: data-summary-diagnose 
#| message: false
#| code-fold: true

# using Diagnose from dlookr to look for column summary
data |> 
  diagnose() |>
  formattable()
```

Checking the number of rows and columns with `nrow` and `ncol`:

```{r}
#| label: No-of-row
#| message: false
#| code-fold: true

# Number of rows in the data
nrow(data)
```

-   So we have totally 602 data points in the Amazon Consumer behavior dataset

```{r}
#| label: No-of-col 
#| message: false
#| code-fold: true
# Number of columns in the data
ncol(data)
```

-   And we have 23 columns in the dataset.

## Categorical variable summary

Using `gtsummary` for table summary (`tbl_summary()`)of selected categorical columns:

```{r}
#| label: gt-summary
#| message: false
#| code-fold: true
# Selecting the required columns for summary 
 new_data <-data %>% select(Browsing_Frequency,Purchase_Frequency,Purchase_Categories)
  
# Using gtsummary
 
new_data |>
  gtsummary::tbl_summary()
```

## Motivation

## Questions

### Question 1

### Question 2

## Analysis plan

-   A plan for answering each of the questions including the variables involved, variables to be created (if any), external data to be merged in (if any).

### Approach for question 1

### Approach for question 2

## Organization

### Plan of Attack

|               Week                | Weekly Tasks                                                           | Persons in Charge |  Backup  |
|:---------------------------------:|------------------------------------------------------------------------|:-----------------:|:--------:|
|       until November 8^th^        | Explore and finalize the dataset and the problem statements            |     Everyone      | Everyone |
|                \-                 | Complete the proposal and assign some high-level tasks                 |     Everyone      | Everyone |
|     November 9^th^ to 15^th^      | Exploratory Data Analysis                                              |        TBD        |   TBD    |
|                \-                 | Data cleaning and Data pre-processing based on EDA                     |        TBD        |   TBD    |
|                \-                 | Question specific exploration and identify initial trends and patterns |        TBD        |   TBD    |
|     November 16^th^ to 22^nd^     | Model training for Q1                                                  |        TBD        |   TBD    |
|                \-                 | Model training for Q2                                                  |        TBD        |   TBD    |
|     November 23^rd^ to 29^th^     | Continue Model training and testing for Q1 and Q2                      |        TBD        |   TBD    |
|                \-                 | Improving the models if there is a need                                |        TBD        |   TBD    |
| November 30^th^ to December 6^th^ | Refining the code for code review with comments                        |        TBD        |   TBD    |
|                \-                 | Generate insights from the model output                                |        TBD        |   TBD    |
|     December 7^th^ to 13^th^      | Review the generated models                                            |        TBD        |   TBD    |
|                \-                 | Write-up and presentation for the project                              |     Everyone      | Everyone |

: {.hover}

### Repo Organization

The following are the folders involved in the Project repository.

-   **'data/':** Used for storing any necessary data files for the project, such as input files.

-   **'images/':** Used for storing image files used in the project.

-   **'presentation_files/':** Folder for having presentation related files.

-   **'\_extra/':** Used to brainstorm our analysis which won't impact our project workflow.

-   **'\_freeze/':** This folder is used to store the generated files during the build process. These files represent the frozen state of the website at a specific point in time.

-   **'\_site/':** Folder used to store the generated static website files after the site generator processes the quarto document.

-   **'.github/':** Folder for storing github templates and workflow.

We will be creating few folders inside `images/` folder for storing question specific images and presentation related images which are generated through out the plot.
